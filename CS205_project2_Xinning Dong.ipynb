{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "import time\n",
    "\n",
    "def forward_selection(data, num_features, num_instances):\n",
    "    best_so_far_accuracy = 0.0\n",
    "    #initialize an empty set\n",
    "    best_subset = [] #initialize the best subset so far for a designated number of features\n",
    "    best_total = [] #the best set among all of different numbers of features.\n",
    "    for i in range(num_features): #start from 0 feature\n",
    "        #flags for checking if the new feature is added to total or subset\n",
    "        add_total = -1\n",
    "        best_subset_accuracy = 0.0\n",
    "        print(\"On the \" , i , \"th level of the search tree\")\n",
    "\n",
    "        for j in range(1, num_features + 1):\n",
    "            if j not in best_subset:\n",
    "                cur_subset = copy.deepcopy(best_subset)\n",
    "                cur_subset.append(j)\n",
    "                \n",
    "                accuracy = leave_one_out_cross_validation(data, cur_subset, num_instances)\n",
    "                print(\"\\tUsing feature(s) \", cur_subset, \" accuracy is \", accuracy, \"%\")\n",
    "                if accuracy > best_so_far_accuracy:\n",
    "                    best_so_far_accuracy = accuracy\n",
    "                    add_total = j\n",
    "                if accuracy > best_subset_accuracy:\n",
    "                    best_subset_accuracy = accuracy\n",
    "                    add_subset = j\n",
    "        \n",
    "        if add_total != -1:\n",
    "            best_subset.append(add_total)\n",
    "            best_total.append(add_total)\n",
    "            print(\"\\n\\nFeature set \", best_subset, \" was best, accuracy is \", best_so_far_accuracy, \"%\\n\\n\")\n",
    "        else:\n",
    "            print(\"\\n\\n(Warning, Accuracy has decreases! Continuing search in case of local maxima)\")\n",
    "            best_subset.append(add_subset)\n",
    "            print(\"Feature set \", best_subset, \" was best, accuracy is \", best_subset_accuracy, \"%\\n\\n\")\n",
    "    #Finished looping all numbers of features\n",
    "    print(\"Finished search!! The best feature subset is \", best_total, \" which has an accuracy of \", best_so_far_accuracy, \"%\")\n",
    "    \n",
    "\n",
    "\n",
    "def backward_elimination(data, num_features, num_instances):\n",
    "    best_so_far_accuracy = 0.0\n",
    "    #initialize a full subset\n",
    "    best_subset = [i+1 for i in range(num_features)] #initialize the best subset so far for a designated number of features\n",
    "    best_total = [i+1 for i in range(num_features)] #the best set among all of different numbers of features.\n",
    "    for i in range(num_features):\n",
    "         #flags for checking if the new feature is added to total or subset\n",
    "        remove_total = -1\n",
    "        best_subset_accuracy = 0.0\n",
    "        print(\"On the \" , i , \"th level of the search tree\")\n",
    "        \n",
    "        for j in range(1, num_features + 1):\n",
    "            if j in best_subset:\n",
    "                cur_subset = copy.deepcopy(best_subset)\n",
    "                cur_subset.remove(j)\n",
    "                \n",
    "                accuracy = leave_one_out_cross_validation(data, cur_subset, num_instances)\n",
    "                print(\"\\tUsing feature(s) \", cur_subset, \" accuracy is \", accuracy, \"%\")\n",
    "                if accuracy > best_so_far_accuracy:\n",
    "                    best_so_far_accuracy = accuracy\n",
    "                    remove_total = j\n",
    "                if accuracy > best_subset_accuracy:\n",
    "                    best_subset_accuracy = accuracy\n",
    "                    remove_subset = j\n",
    "                    \n",
    "        if remove_total != -1:\n",
    "            best_subset.remove(remove_total)\n",
    "            best_total.remove(remove_total)\n",
    "            print(\"\\n\\nFeature set \", best_subset, \" was best, accuracy is \", best_so_far_accuracy, \"%\\n\\n\")\n",
    "        else:\n",
    "            print(\"\\n\\n(Warning, Accuracy has decreases! Continuing search in case of local maxima)\")\n",
    "            best_subset.remove(remove_subset)\n",
    "            print(\"Feature set \", best_subset, \" was best, accuracy is \", best_subset_accuracy, \"%\\n\\n\")\n",
    "    #Finished looping all numbers of features\n",
    "    print(\"Finished search!! The best feature subset is \", best_total, \" which has an accuracy of \", best_so_far_accuracy, \"%\")\n",
    "    \n",
    "\n",
    "    \n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leave_one_out_cross_validation(data, cur_subset, num_instances):\n",
    "    num_corr_classfied = 0\n",
    "    for i in range(num_instances):\n",
    "        nearest_neighbor_location = float(\"inf\")\n",
    "        nearest_neighbor_distance = float(\"inf\")\n",
    "        for j in range(num_instances):\n",
    "            if j == i:\n",
    "                continue\n",
    "            else:\n",
    "                distance = 0\n",
    "                for k in range(len(cur_subset)):\n",
    "                    distance = distance + pow((data[j][cur_subset[k]] - data[i][cur_subset[k]]), 2)\n",
    "                distance = math.sqrt(distance)\n",
    "                \n",
    "                if distance < nearest_neighbor_distance:\n",
    "                    nearest_neighbor_distance = distance\n",
    "                    nearest_neighbor_location = j\n",
    "        \n",
    "        neighbor = nearest_neighbor_location\n",
    "        \n",
    "        if data[neighbor][0] == data[i][0]:\n",
    "            num_corr_classfied += 1\n",
    "    \n",
    "    accuracy = (num_corr_classfied/num_instances) *100\n",
    "    return accuracy\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    print(\"Welcome to Xinning Dong's Feature Selection Algorithm.\")\n",
    "    file = input(\"Type in the name of the file to test: \")\n",
    "    data = open(file, 'r')\n",
    "    \n",
    "    readline = data.readline()\n",
    "    num_features = len(readline.split()) - 1\n",
    "    \n",
    "    data.seek(0)\n",
    "    num_instances = sum(1 for i in data)\n",
    "    data.seek(0)\n",
    "    \n",
    "    #load data as a 2D array\n",
    "    instances = [[] for i in range(num_instances)]\n",
    "    for i in range(num_instances):\n",
    "        instances[i] = [float(j) for j in data.readline().split()]\n",
    "        \n",
    "    \n",
    "    print(\"Type the number of the algorithm you want to run.\")\n",
    "    print(\"1) Forward Selection\")\n",
    "    print(\"2) Backward Elimination\")\n",
    "    switch = int(input())\n",
    "    print(\"This data set has \", num_features, \" features (not including the class attribute), with \", num_instances,\n",
    "          \" instances.\" )\n",
    "        \n",
    "    \n",
    "    #normalize data by deducting average of the data and then devide by the standard deviation of the data\n",
    "    avg = []\n",
    "    for i in range(1, num_features + 1):\n",
    "        avg.append((sum(row[i] for row in instances)) / num_instances)\n",
    "    \n",
    "    std = []\n",
    "    for i in range(1, num_features + 1):\n",
    "        std.append(math.sqrt(sum(pow((row[i] - avg[i-1]), 2) for row in instances) / num_instances))\n",
    "    \n",
    "    for i in range(num_instances):\n",
    "        for j in range(1, num_features + 1):\n",
    "            instances[i][j] = (instances[i][j] - avg[j-1])/std[j-1]\n",
    "    \n",
    "    #run with all features\n",
    "    all_subset = []\n",
    "    for i in range(1, num_features + 1):\n",
    "        all_subset.append(i)\n",
    "    accuracy = leave_one_out_cross_validation(instances, all_subset, num_instances)\n",
    "    print(\"Running nearest neighbor with all \", num_features, \" features, using \\\"leaving-one-out\\\" evaluation, \n",
    "          I get an accuracy of \", accuracy, \"%\")    \n",
    "    \n",
    "    print(\"Beginning search.\\n\\n\")\n",
    "    \n",
    "    if switch == 1:\n",
    "        forward_selection(instances, num_features, num_instances)\n",
    "    elif switch == 2:\n",
    "        backward_elimination(instances, num_features, num_instances)\n",
    "    \n",
    "\n",
    "def timed_run():\n",
    "    start = time.time()\n",
    "    run()\n",
    "    end = time.time()\n",
    "    print(\"Function finishes in \", end-start, \"seconds.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
